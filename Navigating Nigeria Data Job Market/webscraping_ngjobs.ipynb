{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"a4LLK4GCGAs5"},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","from csv import writer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhR7nv_8GTBr"},"outputs":[],"source":["HEADERS = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I24ipciCGrHM"},"outputs":[],"source":["url = 'https://www.myjobmag.com/search/jobs?q=data&currentpage=100'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQjtzKpzG2Xh"},"outputs":[],"source":["page = requests.get(url, headers=HEADERS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HR88Wc8RHHsY"},"outputs":[],"source":["soup = BeautifulSoup(page.content, 'html.parser')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Te2bK-Z8HQM1"},"outputs":[],"source":["cards = soup.find('ul', class_='job-list')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqArFzGNH1qy"},"outputs":[],"source":["card = soup.find_all('li', class_= 'mag-b')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ReXCzv9bJW3Z"},"outputs":[],"source":["job_url = []\n","for link in card:\n","  urls= link.find('a')\n","  links = 'https://myjobmag.com' + urls.get('href')\n","  job_url.append(links)\n","\n","job_urls = job_url[:18]\n","titles = []\n","descriptions = []\n","requirements = []\n","locations = []\n","job_types = []\n","for a in job_urls:\n","  try:\n","    links = a\n","    #print(links)\n","    new_page = requests.get(links, headers = HEADERS)\n","    new_soup = BeautifulSoup(new_page.content, 'html.parser')\n","    title = new_soup.find('span', class_='subjob-title')\n","    titles.append(title.text)\n","    other = new_soup.find('ul', class_='job-key-info')\n","    job_type = other.find('span', class_='jkey-info')\n","    job_types.append(job_type.text)\n","    location = other.find_all('li')[3].find('span', class_='jkey-info')\n","    locations.append(location.text)\n","    description = other.find_all('li')[4].find('span', class_='jkey-info')\n","    descriptions.append(description.text.strip())\n","    job_detail = new_soup.find('div', 'job_details')\n","    ul_element =new_soup.find_all('ul')\n","    if len(ul_element) >= 2:\n","      requirement = ul_element[11].text\n","      requirements.append(requirement.strip())\n","    else:\n","      print('not specified')\n","  except requests.exceptions.RequestException as e:\n","      print('no requirement mentioned')\n","\n","mymag = {'title':titles, 'description':descriptions, 'requirement':requirements, 'location':locations, 'job_type':job_types}\n","df = pd.DataFrame(mymag)\n","df.to_csv(\"myjobmag100.csv\", index=False)\n","    #print(df)\n","    #print(title.text)\n","    #print(location.text)\n","    #print(requirement)\n","    #print(job_type.text, '\\n')\n","\n","  #print(job_url[:17])"]}],"metadata":{"colab":{"provenance":[{"file_id":"13KtN12Sqita0Bgq2dyod6od3cCVMvDYA","timestamp":1707300949968}],"authorship_tag":"ABX9TyMymfITyqabnKjvLySS6nLi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}